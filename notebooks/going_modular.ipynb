{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 11:26:28.190069: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import models, datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchinfo import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "from timeit import default_timer as timer\n",
    "import os\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going Modular Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Going Modular directory exists already, skipping creation\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "parent_folder = os.path.dirname(current_directory)\n",
    "src_folder = parent_folder + \"/src\"\n",
    "\n",
    "going_modular_dir = src_folder + \"/going_modular\"\n",
    "\n",
    "if os.path.isdir(going_modular_dir):\n",
    "  print(f\"[INFO] Going Modular directory exists already, skipping creation\")\n",
    "else:\n",
    "  os.makedirs(going_modular_dir)\n",
    "  print(f\"[INFO] Going Modular directory created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data_setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/kittyli/Desktop/AI and ML/Practices/Garbage Clasification App/src/going_modular/data_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"/Users/kittyli/Desktop/AI and ML/Practices/Garbage Clasification App/src/going_modular/data_setup.py\" \n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import models, datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchinfo import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "from timeit import default_timer as timer\n",
    "import os\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "\n",
    "default_train_transforms = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                               transforms.RandomRotation(30),\n",
    "                                               transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "                                               transforms.GaussianBlur(3),\n",
    "                                               transforms.ToTensor()])\n",
    "\n",
    "\n",
    "def create_auto_transforms(model: torch.nn.Module) -> List[transforms.Compose]:\n",
    "  '''\n",
    "  '''\n",
    "  print(\"[INFO] create_auto_transforms function incomplete\")\n",
    "\n",
    "\n",
    "def create_dataloaders(train_path: str,\n",
    "                       val_path: str,\n",
    "                       test_path: str,\n",
    "                       batch_size: int,\n",
    "                       transforms: list,\n",
    "                       num_workers: int=os.cpu_count()) -> Tuple[DataLoader, DataLoader, DataLoader, List[str]]:\n",
    "  '''\n",
    "  This function creates dataloaders for training, validation, and testing datasets.\n",
    "\n",
    "  Args:\n",
    "    train_path (str): The path to the training dataset\n",
    "    val_path (str): The path to the validation dataset\n",
    "    test_path (str): The path to the testing dataset\n",
    "    batch_size (int): The batch size for the dataloaders\n",
    "    transforms (list): A list of transforms to apply to the datasets\n",
    "    num_workers (int): The number of workers to use for creating dataloaders\n",
    "\n",
    "  Returns:\n",
    "    train_dataloader (DataLoader): The training dataloader\n",
    "    val_dataloader (DataLoader): The validation dataloader\n",
    "    test_dataloader (DataLoader): The testing dataloader\n",
    "    class_names (List[str]): A list of class names\n",
    "  '''\n",
    "  train_data = ImageFolder(train_path, transform=transforms[0])\n",
    "  val_data = ImageFolder(val_path, transform=transforms[1])\n",
    "  test_data = ImageFolder(test_path, transform=transforms[1])\n",
    "\n",
    "  class_names = train_data.classes\n",
    "\n",
    "  train_dataloader = DataLoader(dataset=train_data,\n",
    "                                batch_size=batch_size,\n",
    "                                num_workers=num_workers,\n",
    "                                shuffle=True,\n",
    "                                pin_memory=True)\n",
    "  \n",
    "  val_dataloader = DataLoader(dataset=val_data,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers,\n",
    "                              shuffle=False,\n",
    "                              pin_memory=True)\n",
    "  \n",
    "  test_dataloader = DataLoader(dataset=test_data,\n",
    "                                batch_size=batch_size,\n",
    "                                num_workers=num_workers,\n",
    "                                shuffle=False,\n",
    "                                pin_memory=True)\n",
    "\n",
    "  return train_dataloader, val_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
