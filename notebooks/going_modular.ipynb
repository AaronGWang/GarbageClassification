{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 08:36:47.142879: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import models, datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchinfo import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "from timeit import default_timer as timer\n",
    "import os\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going Modular Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Going Modular directory exists already, skipping creation\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "parent_folder = os.path.dirname(current_directory)\n",
    "src_folder = parent_folder + \"/src\"\n",
    "\n",
    "going_modular_dir = src_folder + \"/going_modular\"\n",
    "\n",
    "if os.path.isdir(going_modular_dir):\n",
    "  print(f\"[INFO] Going Modular directory exists already, skipping creation\")\n",
    "else:\n",
    "  os.makedirs(going_modular_dir)\n",
    "  print(f\"[INFO] Going Modular directory created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data_setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/kittyli/Desktop/AI and ML/Practices/Garbage Clasification App/src/going_modular/data_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"/Users/kittyli/Desktop/AI and ML/Practices/Garbage Clasification App/src/going_modular/data_setup.py\" \n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import models, datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchinfo import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "from timeit import default_timer as timer\n",
    "import os\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "\n",
    "default_train_transforms = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                               transforms.RandomRotation(30),\n",
    "                                               transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "                                               transforms.GaussianBlur(3),\n",
    "                                               transforms.ToTensor()])\n",
    "\n",
    "\n",
    "def create_auto_transforms(model_name: str) -> List[transforms.Compose]:\n",
    "  '''\n",
    "  '''\n",
    "  print(\"[INFO] create_auto_transforms function incomplete\")\n",
    "\n",
    "\n",
    "def create_dataloaders(train_path: str,\n",
    "                       val_path: str,\n",
    "                       test_path: str,\n",
    "                       batch_size: int,\n",
    "                       transforms: list,\n",
    "                       num_workers: int=os.cpu_count()) -> Tuple[DataLoader, DataLoader, DataLoader, List[str]]:\n",
    "  '''\n",
    "  This function creates dataloaders for training, validation, and testing datasets.\n",
    "\n",
    "  Args:\n",
    "    train_path (str): The path to the training dataset\n",
    "    val_path (str): The path to the validation dataset\n",
    "    test_path (str): The path to the testing dataset\n",
    "    batch_size (int): The batch size for the dataloaders\n",
    "    transforms (list): A list of transforms to apply to the datasets\n",
    "    num_workers (int): The number of workers to use for creating dataloaders\n",
    "\n",
    "  Returns:\n",
    "    train_dataloader (DataLoader): The training dataloader\n",
    "    val_dataloader (DataLoader): The validation dataloader\n",
    "    test_dataloader (DataLoader): The testing dataloader\n",
    "    class_names (List[str]): A list of class names\n",
    "  '''\n",
    "  train_data = ImageFolder(train_path, transform=transforms[0])\n",
    "  val_data = ImageFolder(val_path, transform=transforms[1])\n",
    "  test_data = ImageFolder(test_path, transform=transforms[1])\n",
    "\n",
    "  class_names = train_data.classes\n",
    "\n",
    "  train_dataloader = DataLoader(dataset=train_data,\n",
    "                                batch_size=batch_size,\n",
    "                                num_workers=num_workers,\n",
    "                                shuffle=True,\n",
    "                                pin_memory=True)\n",
    "  \n",
    "  val_dataloader = DataLoader(dataset=val_data,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers,\n",
    "                              shuffle=False,\n",
    "                              pin_memory=True)\n",
    "  \n",
    "  test_dataloader = DataLoader(dataset=test_data,\n",
    "                                batch_size=batch_size,\n",
    "                                num_workers=num_workers,\n",
    "                                shuffle=False,\n",
    "                                pin_memory=True)\n",
    "\n",
    "  return train_dataloader, val_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/kittyli/Desktop/AI and ML/Practices/Garbage Clasification App/src/going_modular/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"/Users/kittyli/Desktop/AI and ML/Practices/Garbage Clasification App/src/going_modular/utils.py\" \n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import models, datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchinfo import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "from timeit import default_timer as timer\n",
    "import os\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "from data_setup import create_auto_transforms\n",
    "\n",
    "def set_seeds(seed: int=42) -> None:\n",
    "  '''\n",
    "  This function sets manual seeds for reproducibility.\n",
    "\n",
    "  Args:\n",
    "    seed (int): The seed value to use\n",
    "\n",
    "  Returns:\n",
    "    None\n",
    "  '''\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed(42)\n",
    "  random.seed(42)\n",
    "\n",
    "\n",
    "def save_model(model: torch.nn.Module, target_dir: str, model_name: str) -> None:\n",
    "  '''\n",
    "  This function saves a model to a specified directory.\n",
    "\n",
    "  Args:\n",
    "    model (torch.nn.Module): The model to save\n",
    "    target_dir (str): The directory to save the model\n",
    "    model_name (str): The name to save the model as\n",
    "\n",
    "  Returns:\n",
    "    None\n",
    "  '''\n",
    "  target_dir_path = Path(target_dir)\n",
    "  target_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "  assert model_name.endswith('.pt') or model_name.endswith(\".pth\"), \"[ERROR] Model name must end with .pt or .pth\"\n",
    "  model_save_path = target_dir_path / model_name\n",
    "\n",
    "  print(f\"[INFO] Saving model to: {model_save_path}\")\n",
    "  torch.save(obj=model.state_dict(), f=model_save_path)\n",
    "\n",
    "\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               test_dataloader: DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               device: torch.device) -> Tuple[float, float]:\n",
    "  '''\n",
    "  This function evaluates a model on a test dataset.\n",
    "\n",
    "  Args:\n",
    "    model (torch.nn.Module): The model to evaluate\n",
    "    test_dataloader (DataLoader): The dataloader for the test dataset\n",
    "    loss_fn (torch.nn.Module): The loss function to use\n",
    "    device (torch.device): The device to use for evaluation\n",
    "\n",
    "  Returns:\n",
    "    test_loss (float): The loss on the test dataset\n",
    "    test_acc (float): The accuracy on the test dataset\n",
    "  '''\n",
    "  test_loss, test_acc = 0, 0\n",
    "\n",
    "  model.eval()\n",
    "  with torch.inference_mode():\n",
    "    for batch, (X, y) in enumerate(test_dataloader):\n",
    "      X, y = X.to(device), y.to(device)\n",
    "\n",
    "      test_logits = model(X)\n",
    "      loss = loss_fn(test_logits, y)\n",
    "\n",
    "      test_loss += loss.item()\n",
    "\n",
    "      test_labels = torch.argmax(test_logits, dim=1)\n",
    "      test_acc += ((test_labels == y).sum().item()/len(test_labels))\n",
    "\n",
    "  test_loss /= len(test_dataloader)\n",
    "  test_acc /= len(test_dataloader)\n",
    "\n",
    "  return test_loss, test_acc\n",
    "\n",
    "\n",
    "def custom_eval(model: torch.nn.Module,\n",
    "                model_name: str,\n",
    "                image_path: str,\n",
    "                class_names: List[str],\n",
    "                device: torch.device) -> Tuple[str, float]:\n",
    "  '''\n",
    "  This function predicts on a custom image.\n",
    "\n",
    "  Args:\n",
    "    model (torch.nn.Module): The model to use for prediction\n",
    "    model_name (str): The name of the model\n",
    "    image_path (str): The path to the image\n",
    "    class_names (list): The class names for the model\n",
    "    device (torch.device): The device to use for prediction\n",
    "\n",
    "  Returns:\n",
    "    pred_class (str): The predicted class\n",
    "    pred_prob (float): The predicted probability\n",
    "  '''\n",
    "\n",
    "  auto_transforms = create_auto_transforms(model_name)\n",
    "\n",
    "  image = Image.open(image_path)\n",
    "  transformed_image = auto_transforms(image).unsqueeze(dim=1).to(device)\n",
    "\n",
    "  model.to(device)\n",
    "  model.eval()\n",
    "\n",
    "  with torch.inference_mode():\n",
    "    pred_logits = model(transformed_image)\n",
    "    pred_probs = torch.softmax(pred_logits, dim=1)\n",
    "    pred_label = pred_logits.argmax(dim=1)\n",
    "\n",
    "    pred_class = class_names[pred_label]\n",
    "    pred_prob = pred_probs.max()\n",
    "  \n",
    "  return pred_class, pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
